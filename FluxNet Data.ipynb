{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "29cdcf1e",
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import random\n",
    "\n",
    "from datetime import datetime"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "d1bfd7e1",
   "metadata": {},
   "source": [
    "Importing 15 original flux net files for variable analysis"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "401abcbe",
   "metadata": {},
   "outputs": [],
   "source": [
    "# FluxNet Sites Upload\n",
    "# Australia, Calperum - Savanna\n",
    "AU_CPR = pd.read_csv('FLX_AU-Cpr_FLUXNET2015_FULLSET_DD_2010-2014_2-4.csv')\n",
    "# Australia, Ti tree East - Grassland\n",
    "AU_TTE = pd.read_csv('FLX_AU-TTE_FLUXNET2015_FULLSET_DD_2012-2014_1-4.csv')\n",
    "# Switzerland, Chamau - Grassland\n",
    "CH_CHA = pd.read_csv('FLX_CH-Cha_FLUXNET2015_FULLSET_DD_2005-2014_2-4.csv')\n",
    "# Germany, Selhausen Juelich - Cropland\n",
    "DE_RUS = pd.read_csv('FLX_DE-RuS_FLUXNET2015_FULLSET_DD_2011-2014_1-4.csv')\n",
    "# Germany, Schechenfilz - Permanent Wetland\n",
    "DE_SFN = pd.read_csv('FLX_DE-SfN_FLUXNET2015_FULLSET_DD_2012-2014_1-4.csv')\n",
    "# French Guiana, Guyaflux - Evergreen Broadleaf Forest\n",
    "GF_GUY = pd.read_csv('FLX_GF-Guy_FLUXNET2015_FULLSET_DD_2004-2014_2-4.csv')\n",
    "# Ghana, Ankasa - Evergreen Broadleaf Forest\n",
    "GH_ANK = pd.read_csv('FLX_GH-Ank_FLUXNET2015_FULLSET_DD_2011-2014_1-4.csv')\n",
    "# Italy, Collelongo - Deciduous Broadleaf Forest\n",
    "IT_COL = pd.read_csv('FLX_IT-Col_FLUXNET2015_FULLSET_DD_1996-2014_1-4.csv')\n",
    "# Italy, Arca di Noe - Closed Shrubland\n",
    "IT_NOE = pd.read_csv('FLX_IT-Noe_FLUXNET2015_FULLSET_DD_2004-2014_2-4.csv')\n",
    "# USA, Park Falls - Mixed Forest\n",
    "US_PFA = pd.read_csv('FLX_US-PFa_FLUXNET2015_FULLSET_DD_1995-2014_1-4.csv')\n",
    "# USA, Santa Rita Mesquite - Woody Savanna\n",
    "US_SRM = pd.read_csv('FLX_US-SRM_FLUXNET2015_FULLSET_DD_2004-2014_1-4.csv')\n",
    "# USA, Twitchell Alfalfa - Cropland\n",
    "US_TW3 = pd.read_csv('FLX_US-Tw3_FLUXNET2015_FULLSET_DD_2013-2014_2-4.csv')\n",
    "# USA, Willow Creek - Deciduous Broadleaf Forest\n",
    "US_WCR = pd.read_csv('FLX_US-WCr_FLUXNET2015_FULLSET_DD_1999-2014_1-4.csv')\n",
    "# USA, Walnut Gulch - Open Shrubland\n",
    "US_WHS = pd.read_csv('FLX_US-Whs_FLUXNET2015_FULLSET_DD_2007-2014_1-4.csv')\n",
    "# USA, Walnut Gulch - Grassland\n",
    "US_WKG = pd.read_csv('FLX_US-Wkg_FLUXNET2015_FULLSET_DD_2004-2014_1-4.csv')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "id": "2e7ca3e8",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "AU_CPR End Date: 20141231\n",
      "AU_TTE End Date: 20141231\n",
      "CH_CHA End Date: 20141231\n",
      "DE_RUS End Date: 20141231\n",
      "DE_SFN End Date: 20141231\n",
      "GF_GUY End Date: 20141231\n",
      "GH_ANK End Date: 20141231\n",
      "IT_COL End Date: 20141231\n",
      "IT_NOE End Date: 20141231\n",
      "US_PFA End Date: 20141231\n",
      "US_SRM End Date: 20141231\n",
      "US_TW3 End Date: 20141231\n",
      "US_WCR End Date: 20141231\n",
      "US_WHS End Date: 20141231\n",
      "US_WKG End Date: 20141231\n"
     ]
    }
   ],
   "source": [
    "print('AU_CPR End Date: ' + str(AU_CPR['TIMESTAMP'].max()))\n",
    "print('AU_TTE End Date: ' + str(AU_TTE['TIMESTAMP'].max()))\n",
    "print('CH_CHA End Date: ' + str(CH_CHA['TIMESTAMP'].max()))\n",
    "print('DE_RUS End Date: ' + str(DE_RUS['TIMESTAMP'].max()))\n",
    "print('DE_SFN End Date: ' + str(DE_SFN['TIMESTAMP'].max()))\n",
    "print('GF_GUY End Date: ' + str(GF_GUY['TIMESTAMP'].max()))\n",
    "print('GH_ANK End Date: ' + str(GH_ANK['TIMESTAMP'].max()))\n",
    "print('IT_COL End Date: ' + str(IT_COL['TIMESTAMP'].max()))\n",
    "print('IT_NOE End Date: ' + str(IT_NOE['TIMESTAMP'].max()))\n",
    "print('US_PFA End Date: ' + str(US_PFA['TIMESTAMP'].max()))\n",
    "print('US_SRM End Date: ' + str(US_SRM['TIMESTAMP'].max()))\n",
    "print('US_TW3 End Date: ' + str(US_TW3['TIMESTAMP'].max()))\n",
    "print('US_WCR End Date: ' + str(US_WCR['TIMESTAMP'].max()))\n",
    "print('US_WHS End Date: ' + str(US_WHS['TIMESTAMP'].max()))\n",
    "print('US_WKG End Date: ' + str(US_WKG['TIMESTAMP'].max()))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "cd72731f",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "15"
      ]
     },
     "execution_count": 3,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "datasets = {'AU_CPR':AU_CPR, 'AU_TTE':AU_TTE, 'CH_CHA':CH_CHA, 'DE_RUS':DE_RUS, 'DE_SFN':DE_SFN, \n",
    "            'GF_GUY':GF_GUY, 'GH_ANK':GH_ANK, 'IT_COL':IT_COL, 'IT_NOE':IT_NOE, 'US_PFA':US_PFA, \n",
    "            'US_SRM':US_SRM, 'US_TW3':US_TW3, 'US_WCR':US_WCR, 'US_WHS':US_WHS, 'US_WKG':US_WKG}\n",
    "len(datasets)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "79230325",
   "metadata": {},
   "source": [
    "Checking for number of available dates in investigation period and using more represented days as the final sample"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "f1c1bb28",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Available Days for AU_CPR: 117\n",
      "Available Days for AU_TTE: 55\n",
      "Available Days for CH_CHA: 117\n",
      "Available Days for DE_RUS: 85\n",
      "Available Days for DE_SFN: 117\n",
      "Available Days for GF_GUY: 117\n",
      "Available Days for GH_ANK: 117\n",
      "Available Days for IT_COL: 111\n",
      "Available Days for IT_NOE: 117\n",
      "Available Days for US_PFA: 82\n",
      "Available Days for US_SRM: 115\n",
      "Available Days for US_TW3: 117\n",
      "Available Days for US_WCR: 74\n",
      "Available Days for US_WHS: 117\n",
      "Available Days for US_WKG: 117\n"
     ]
    }
   ],
   "source": [
    "for name, df in datasets.items():\n",
    "    filtered_df = df[(df['TIMESTAMP'] >= 20140906) & (df['TIMESTAMP'] <= 20141231) & (df['GPP_DT_VUT_REF'] != 0)]\n",
    "    datasets[name] = filtered_df  \n",
    "    print(f'Available Days for {name}: {len(filtered_df)}')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "abe95114",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "TIMESTAMP: 20140906, Count: 14, Missing Datasets: ['AU_TTE']\n",
      "TIMESTAMP: 20140907, Count: 14, Missing Datasets: ['AU_TTE']\n",
      "TIMESTAMP: 20140908, Count: 14, Missing Datasets: ['AU_TTE']\n",
      "TIMESTAMP: 20140909, Count: 14, Missing Datasets: ['AU_TTE']\n",
      "TIMESTAMP: 20140910, Count: 14, Missing Datasets: ['AU_TTE']\n",
      "TIMESTAMP: 20140911, Count: 14, Missing Datasets: ['AU_TTE']\n",
      "TIMESTAMP: 20140912, Count: 14, Missing Datasets: ['AU_TTE']\n",
      "TIMESTAMP: 20140913, Count: 14, Missing Datasets: ['AU_TTE']\n",
      "TIMESTAMP: 20140914, Count: 14, Missing Datasets: ['AU_TTE']\n",
      "TIMESTAMP: 20140915, Count: 14, Missing Datasets: ['AU_TTE']\n",
      "TIMESTAMP: 20140916, Count: 14, Missing Datasets: ['AU_TTE']\n",
      "TIMESTAMP: 20140917, Count: 14, Missing Datasets: ['AU_TTE']\n",
      "TIMESTAMP: 20140918, Count: 14, Missing Datasets: ['AU_TTE']\n",
      "TIMESTAMP: 20140919, Count: 14, Missing Datasets: ['AU_TTE']\n",
      "TIMESTAMP: 20140920, Count: 14, Missing Datasets: ['AU_TTE']\n",
      "TIMESTAMP: 20140921, Count: 14, Missing Datasets: ['AU_TTE']\n",
      "TIMESTAMP: 20140922, Count: 14, Missing Datasets: ['AU_TTE']\n",
      "TIMESTAMP: 20140923, Count: 14, Missing Datasets: ['AU_TTE']\n",
      "TIMESTAMP: 20140924, Count: 14, Missing Datasets: ['AU_TTE']\n",
      "TIMESTAMP: 20140925, Count: 14, Missing Datasets: ['AU_TTE']\n",
      "TIMESTAMP: 20140926, Count: 14, Missing Datasets: ['AU_TTE']\n",
      "TIMESTAMP: 20140927, Count: 14, Missing Datasets: ['AU_TTE']\n",
      "TIMESTAMP: 20140928, Count: 14, Missing Datasets: ['AU_TTE']\n",
      "TIMESTAMP: 20140929, Count: 14, Missing Datasets: ['AU_TTE']\n",
      "TIMESTAMP: 20141010, Count: 14, Missing Datasets: ['DE_RUS']\n",
      "TIMESTAMP: 20141011, Count: 14, Missing Datasets: ['DE_RUS']\n",
      "TIMESTAMP: 20141012, Count: 14, Missing Datasets: ['DE_RUS']\n",
      "TIMESTAMP: 20141013, Count: 14, Missing Datasets: ['DE_RUS']\n",
      "TIMESTAMP: 20141016, Count: 14, Missing Datasets: ['DE_RUS']\n",
      "TIMESTAMP: 20141017, Count: 14, Missing Datasets: ['DE_RUS']\n",
      "TIMESTAMP: 20141018, Count: 14, Missing Datasets: ['DE_RUS']\n",
      "TIMESTAMP: 20141019, Count: 14, Missing Datasets: ['DE_RUS']\n",
      "TIMESTAMP: 20141028, Count: 14, Missing Datasets: ['DE_RUS']\n",
      "TIMESTAMP: 20141029, Count: 14, Missing Datasets: ['DE_RUS']\n",
      "TIMESTAMP: 20141030, Count: 14, Missing Datasets: ['DE_RUS']\n",
      "TIMESTAMP: 20141031, Count: 14, Missing Datasets: ['DE_RUS']\n",
      "TIMESTAMP: 20141101, Count: 14, Missing Datasets: ['AU_TTE']\n",
      "TIMESTAMP: 20141102, Count: 14, Missing Datasets: ['AU_TTE']\n",
      "TIMESTAMP: 20141103, Count: 14, Missing Datasets: ['AU_TTE']\n",
      "TIMESTAMP: 20141104, Count: 14, Missing Datasets: ['AU_TTE']\n",
      "TIMESTAMP: 20141105, Count: 14, Missing Datasets: ['AU_TTE']\n",
      "TIMESTAMP: 20141106, Count: 14, Missing Datasets: ['AU_TTE']\n",
      "TIMESTAMP: 20141107, Count: 14, Missing Datasets: ['AU_TTE']\n",
      "TIMESTAMP: 20141108, Count: 14, Missing Datasets: ['AU_TTE']\n",
      "TIMESTAMP: 20141109, Count: 14, Missing Datasets: ['AU_TTE']\n",
      "TIMESTAMP: 20141110, Count: 14, Missing Datasets: ['AU_TTE']\n",
      "TIMESTAMP: 20141111, Count: 14, Missing Datasets: ['AU_TTE']\n",
      "TIMESTAMP: 20141112, Count: 14, Missing Datasets: ['AU_TTE']\n",
      "TIMESTAMP: 20141211, Count: 14, Missing Datasets: ['US_WCR']\n",
      "TIMESTAMP: 20141212, Count: 14, Missing Datasets: ['US_WCR']\n",
      "TIMESTAMP: 20141221, Count: 14, Missing Datasets: ['IT_COL']\n",
      "TIMESTAMP: 20141222, Count: 14, Missing Datasets: ['IT_COL']\n",
      "TIMESTAMP: 20141223, Count: 15, Missing Datasets: []\n",
      "TIMESTAMP: 20141224, Count: 15, Missing Datasets: []\n",
      "TIMESTAMP: 20141225, Count: 14, Missing Datasets: ['US_WCR']\n",
      "TIMESTAMP: 20141226, Count: 14, Missing Datasets: ['US_WCR']\n",
      "TIMESTAMP: 20141227, Count: 14, Missing Datasets: ['US_WCR']\n",
      "TIMESTAMP: 20141228, Count: 14, Missing Datasets: ['US_WCR']\n",
      "TIMESTAMP: 20141229, Count: 14, Missing Datasets: ['US_WCR']\n",
      "TIMESTAMP: 20141230, Count: 14, Missing Datasets: ['US_WCR']\n",
      "Available days: 60\n"
     ]
    }
   ],
   "source": [
    "available_days = datasets['AU_CPR']['TIMESTAMP'].tolist()\n",
    "\n",
    "# Dictionary to store the count of datasets each TIMESTAMP is present in\n",
    "day_info = {timestamp: {'count': 0, 'missing_datasets': []} for timestamp in available_days}\n",
    "\n",
    "# Loop through each dataset and count occurrences of each TIMESTAMP\n",
    "for key, df in datasets.items():\n",
    "    for timestamp in available_days:\n",
    "        if timestamp in df['TIMESTAMP'].values:\n",
    "            day_info[timestamp]['count'] += 1\n",
    "        else:\n",
    "            day_info[timestamp]['missing_datasets'].append(key)\n",
    "\n",
    "# Prepare the final list of results\n",
    "result = [(timestamp, info['count'], info['missing_datasets']) for timestamp, info in day_info.items()]\n",
    "\n",
    "# Output the result\n",
    "days_14plus = 0\n",
    "days = []\n",
    "for timestamp, count, missing_datasets in result:\n",
    "    if count >= 14:\n",
    "        days_14plus += 1\n",
    "        days.append(timestamp)\n",
    "        print(f\"TIMESTAMP: {timestamp}, Count: {count}, Missing Datasets: {missing_datasets}\")\n",
    "print(f\"Available days: {days_14plus}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "e1096b08",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[20140906,\n",
       " 20140907,\n",
       " 20140914,\n",
       " 20140917,\n",
       " 20140918,\n",
       " 20140919,\n",
       " 20140921,\n",
       " 20140923,\n",
       " 20140925,\n",
       " 20141010,\n",
       " 20141011,\n",
       " 20141017,\n",
       " 20141018,\n",
       " 20141028,\n",
       " 20141031,\n",
       " 20141103,\n",
       " 20141105,\n",
       " 20141108,\n",
       " 20141212,\n",
       " 20141221,\n",
       " 20141222,\n",
       " 20141223,\n",
       " 20141226,\n",
       " 20141228,\n",
       " 20141230]"
      ]
     },
     "execution_count": 8,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "days_sample = random.sample(days, 25)\n",
    "days_sample.sort()\n",
    "days_sample"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a0e512f5",
   "metadata": {},
   "source": [
    "Concatenating all fluxnet datasets together for final validation data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "578b0295",
   "metadata": {},
   "outputs": [],
   "source": [
    "filtered_datasets = []\n",
    "\n",
    "for name, df in datasets.items():\n",
    "    # Filter the dataset to include only rows with timestamps in days_sample\n",
    "    filtered_df = df.loc[df['TIMESTAMP'].isin(days_sample)].copy()\n",
    "    \n",
    "    # Adding a site identifier to the dataset\n",
    "    filtered_df['SITE'] = name\n",
    "    \n",
    "    # Append the filtered dataset to the list\n",
    "    filtered_datasets.append(filtered_df)\n",
    "\n",
    "# Concatenate all filtered datasets together\n",
    "final_df = pd.concat(filtered_datasets)\n",
    "\n",
    "# Sort the concatenated dataset by timestamp\n",
    "final_df = final_df.sort_values(by='TIMESTAMP')\n",
    "\n",
    "# Set the timestamp as the index\n",
    "final_df.set_index('TIMESTAMP', inplace=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "5d54a89b",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>SITE</th>\n",
       "      <th>GPP_DT_VUT_REF</th>\n",
       "      <th>GPP_NT_VUT_REF</th>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>TIMESTAMP</th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>20140906</th>\n",
       "      <td>AU_CPR</td>\n",
       "      <td>0.647516</td>\n",
       "      <td>1.016490</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>20140906</th>\n",
       "      <td>US_SRM</td>\n",
       "      <td>1.796420</td>\n",
       "      <td>0.319892</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>20140906</th>\n",
       "      <td>US_PFA</td>\n",
       "      <td>4.074350</td>\n",
       "      <td>5.964680</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>20140906</th>\n",
       "      <td>US_WCR</td>\n",
       "      <td>10.009200</td>\n",
       "      <td>9.311300</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>20140906</th>\n",
       "      <td>IT_NOE</td>\n",
       "      <td>0.769989</td>\n",
       "      <td>1.378470</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>20141230</th>\n",
       "      <td>AU_TTE</td>\n",
       "      <td>1.696490</td>\n",
       "      <td>1.905130</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>20141230</th>\n",
       "      <td>DE_RUS</td>\n",
       "      <td>0.570375</td>\n",
       "      <td>0.479853</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>20141230</th>\n",
       "      <td>CH_CHA</td>\n",
       "      <td>0.516711</td>\n",
       "      <td>0.589990</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>20141230</th>\n",
       "      <td>GH_ANK</td>\n",
       "      <td>5.072530</td>\n",
       "      <td>8.170280</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>20141230</th>\n",
       "      <td>US_WKG</td>\n",
       "      <td>0.192722</td>\n",
       "      <td>0.177194</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>351 rows × 3 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "             SITE  GPP_DT_VUT_REF  GPP_NT_VUT_REF\n",
       "TIMESTAMP                                        \n",
       "20140906   AU_CPR        0.647516        1.016490\n",
       "20140906   US_SRM        1.796420        0.319892\n",
       "20140906   US_PFA        4.074350        5.964680\n",
       "20140906   US_WCR       10.009200        9.311300\n",
       "20140906   IT_NOE        0.769989        1.378470\n",
       "...           ...             ...             ...\n",
       "20141230   AU_TTE        1.696490        1.905130\n",
       "20141230   DE_RUS        0.570375        0.479853\n",
       "20141230   CH_CHA        0.516711        0.589990\n",
       "20141230   GH_ANK        5.072530        8.170280\n",
       "20141230   US_WKG        0.192722        0.177194\n",
       "\n",
       "[351 rows x 3 columns]"
      ]
     },
     "execution_count": 10,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "final_df[['SITE','GPP_DT_VUT_REF','GPP_NT_VUT_REF']]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "7fa924d6",
   "metadata": {},
   "outputs": [],
   "source": [
    "final_df.to_excel('FLUXNET Validation Data.xlsx')"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "3fd4cdb9",
   "metadata": {},
   "source": [
    "Validation Data"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "05b7cf97",
   "metadata": {},
   "source": [
    "Following same process for validation data as above"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "84420a73",
   "metadata": {},
   "outputs": [],
   "source": [
    "# FluxNet Sites Upload\n",
    "# Netherlands, Loobos - Evergreen Needleleaf Forest\n",
    "NL_LOO = pd.read_csv('FLX_NL-Loo_FLUXNET2015_FULLSET_DD_1996-2014_1-4.csv')\n",
    "# France, Puechabon - Evergreen Broadleaf Forest\n",
    "FR_PUE = pd.read_csv('FLX_FR-Pue_FLUXNET2015_FULLSET_DD_2000-2014_2-4.csv')\n",
    "# US, Niwot Ridge Forest - Evergreen Needleleaf Forest\n",
    "US_NR1 = pd.read_csv('FLX_US-NR1_FLUXNET2015_FULLSET_DD_1998-2014_1-4.csv')\n",
    "# Australia, Gingin - Grasslands\n",
    "AU_GIN = pd.read_csv('FLX_AU-Gin_FLUXNET2015_FULLSET_DD_2011-2014_1-4.csv')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "30c79716",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "15"
      ]
     },
     "execution_count": 4,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "datasets = {'AU_CPR':AU_CPR, 'CH_CHA':CH_CHA, 'DE_RUS':DE_RUS, 'FR_PUE':FR_PUE, 'GF_GUY':GF_GUY, \n",
    "            'GH_ANK':GH_ANK, 'IT_COL':IT_COL, 'IT_NOE':IT_NOE, 'NL_LOO':NL_LOO, 'US_NR1':US_NR1,\n",
    "            'US_PFA':US_PFA, 'US_SRM':US_SRM, 'US_WCR':US_WCR, 'US_WKG':US_WKG, 'AU_GIN':AU_GIN}\n",
    "len(datasets)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "fd9a290f",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Available Days for AU_CPR: 972\n",
      "Available Days for CH_CHA: 1094\n",
      "Available Days for DE_RUS: 1054\n",
      "Available Days for FR_PUE: 1096\n",
      "Available Days for GF_GUY: 1096\n",
      "Available Days for GH_ANK: 731\n",
      "Available Days for IT_COL: 966\n",
      "Available Days for IT_NOE: 1096\n",
      "Available Days for NL_LOO: 1095\n",
      "Available Days for US_NR1: 913\n",
      "Available Days for US_PFA: 874\n",
      "Available Days for US_SRM: 1068\n",
      "Available Days for US_WCR: 700\n",
      "Available Days for US_WKG: 1020\n",
      "Available Days for AU_GIN: 1096\n"
     ]
    }
   ],
   "source": [
    "for name, df in datasets.items():\n",
    "    filtered_df = df[(df['TIMESTAMP'] >= 20120101) & (df['TIMESTAMP'] <= 20141231) & (df['GPP_DT_VUT_REF'] != 0)]\n",
    "    datasets[name] = filtered_df  \n",
    "    print(f'Available Days for {name}: {len(filtered_df)}')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "9f82c720",
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\joearthur\\AppData\\Local\\Temp\\ipykernel_33048\\56103037.py:4: SettingWithCopyWarning: \n",
      "A value is trying to be set on a copy of a slice from a DataFrame.\n",
      "Try using .loc[row_indexer,col_indexer] = value instead\n",
      "\n",
      "See the caveats in the documentation: https://pandas.pydata.org/pandas-docs/stable/user_guide/indexing.html#returning-a-view-versus-a-copy\n",
      "  df['TIMESTAMP'] = df['TIMESTAMP'].astype(str)\n",
      "C:\\Users\\joearthur\\AppData\\Local\\Temp\\ipykernel_33048\\56103037.py:4: SettingWithCopyWarning: \n",
      "A value is trying to be set on a copy of a slice from a DataFrame.\n",
      "Try using .loc[row_indexer,col_indexer] = value instead\n",
      "\n",
      "See the caveats in the documentation: https://pandas.pydata.org/pandas-docs/stable/user_guide/indexing.html#returning-a-view-versus-a-copy\n",
      "  df['TIMESTAMP'] = df['TIMESTAMP'].astype(str)\n",
      "C:\\Users\\joearthur\\AppData\\Local\\Temp\\ipykernel_33048\\56103037.py:4: SettingWithCopyWarning: \n",
      "A value is trying to be set on a copy of a slice from a DataFrame.\n",
      "Try using .loc[row_indexer,col_indexer] = value instead\n",
      "\n",
      "See the caveats in the documentation: https://pandas.pydata.org/pandas-docs/stable/user_guide/indexing.html#returning-a-view-versus-a-copy\n",
      "  df['TIMESTAMP'] = df['TIMESTAMP'].astype(str)\n",
      "C:\\Users\\joearthur\\AppData\\Local\\Temp\\ipykernel_33048\\56103037.py:4: SettingWithCopyWarning: \n",
      "A value is trying to be set on a copy of a slice from a DataFrame.\n",
      "Try using .loc[row_indexer,col_indexer] = value instead\n",
      "\n",
      "See the caveats in the documentation: https://pandas.pydata.org/pandas-docs/stable/user_guide/indexing.html#returning-a-view-versus-a-copy\n",
      "  df['TIMESTAMP'] = df['TIMESTAMP'].astype(str)\n",
      "C:\\Users\\joearthur\\AppData\\Local\\Temp\\ipykernel_33048\\56103037.py:4: SettingWithCopyWarning: \n",
      "A value is trying to be set on a copy of a slice from a DataFrame.\n",
      "Try using .loc[row_indexer,col_indexer] = value instead\n",
      "\n",
      "See the caveats in the documentation: https://pandas.pydata.org/pandas-docs/stable/user_guide/indexing.html#returning-a-view-versus-a-copy\n",
      "  df['TIMESTAMP'] = df['TIMESTAMP'].astype(str)\n",
      "C:\\Users\\joearthur\\AppData\\Local\\Temp\\ipykernel_33048\\56103037.py:4: SettingWithCopyWarning: \n",
      "A value is trying to be set on a copy of a slice from a DataFrame.\n",
      "Try using .loc[row_indexer,col_indexer] = value instead\n",
      "\n",
      "See the caveats in the documentation: https://pandas.pydata.org/pandas-docs/stable/user_guide/indexing.html#returning-a-view-versus-a-copy\n",
      "  df['TIMESTAMP'] = df['TIMESTAMP'].astype(str)\n",
      "C:\\Users\\joearthur\\AppData\\Local\\Temp\\ipykernel_33048\\56103037.py:4: SettingWithCopyWarning: \n",
      "A value is trying to be set on a copy of a slice from a DataFrame.\n",
      "Try using .loc[row_indexer,col_indexer] = value instead\n",
      "\n",
      "See the caveats in the documentation: https://pandas.pydata.org/pandas-docs/stable/user_guide/indexing.html#returning-a-view-versus-a-copy\n",
      "  df['TIMESTAMP'] = df['TIMESTAMP'].astype(str)\n",
      "C:\\Users\\joearthur\\AppData\\Local\\Temp\\ipykernel_33048\\56103037.py:4: SettingWithCopyWarning: \n",
      "A value is trying to be set on a copy of a slice from a DataFrame.\n",
      "Try using .loc[row_indexer,col_indexer] = value instead\n",
      "\n",
      "See the caveats in the documentation: https://pandas.pydata.org/pandas-docs/stable/user_guide/indexing.html#returning-a-view-versus-a-copy\n",
      "  df['TIMESTAMP'] = df['TIMESTAMP'].astype(str)\n",
      "C:\\Users\\joearthur\\AppData\\Local\\Temp\\ipykernel_33048\\56103037.py:4: SettingWithCopyWarning: \n",
      "A value is trying to be set on a copy of a slice from a DataFrame.\n",
      "Try using .loc[row_indexer,col_indexer] = value instead\n",
      "\n",
      "See the caveats in the documentation: https://pandas.pydata.org/pandas-docs/stable/user_guide/indexing.html#returning-a-view-versus-a-copy\n",
      "  df['TIMESTAMP'] = df['TIMESTAMP'].astype(str)\n",
      "C:\\Users\\joearthur\\AppData\\Local\\Temp\\ipykernel_33048\\56103037.py:4: SettingWithCopyWarning: \n",
      "A value is trying to be set on a copy of a slice from a DataFrame.\n",
      "Try using .loc[row_indexer,col_indexer] = value instead\n",
      "\n",
      "See the caveats in the documentation: https://pandas.pydata.org/pandas-docs/stable/user_guide/indexing.html#returning-a-view-versus-a-copy\n",
      "  df['TIMESTAMP'] = df['TIMESTAMP'].astype(str)\n",
      "C:\\Users\\joearthur\\AppData\\Local\\Temp\\ipykernel_33048\\56103037.py:4: SettingWithCopyWarning: \n",
      "A value is trying to be set on a copy of a slice from a DataFrame.\n",
      "Try using .loc[row_indexer,col_indexer] = value instead\n",
      "\n",
      "See the caveats in the documentation: https://pandas.pydata.org/pandas-docs/stable/user_guide/indexing.html#returning-a-view-versus-a-copy\n",
      "  df['TIMESTAMP'] = df['TIMESTAMP'].astype(str)\n",
      "C:\\Users\\joearthur\\AppData\\Local\\Temp\\ipykernel_33048\\56103037.py:4: SettingWithCopyWarning: \n",
      "A value is trying to be set on a copy of a slice from a DataFrame.\n",
      "Try using .loc[row_indexer,col_indexer] = value instead\n",
      "\n",
      "See the caveats in the documentation: https://pandas.pydata.org/pandas-docs/stable/user_guide/indexing.html#returning-a-view-versus-a-copy\n",
      "  df['TIMESTAMP'] = df['TIMESTAMP'].astype(str)\n",
      "C:\\Users\\joearthur\\AppData\\Local\\Temp\\ipykernel_33048\\56103037.py:4: SettingWithCopyWarning: \n",
      "A value is trying to be set on a copy of a slice from a DataFrame.\n",
      "Try using .loc[row_indexer,col_indexer] = value instead\n",
      "\n",
      "See the caveats in the documentation: https://pandas.pydata.org/pandas-docs/stable/user_guide/indexing.html#returning-a-view-versus-a-copy\n",
      "  df['TIMESTAMP'] = df['TIMESTAMP'].astype(str)\n",
      "C:\\Users\\joearthur\\AppData\\Local\\Temp\\ipykernel_33048\\56103037.py:4: SettingWithCopyWarning: \n",
      "A value is trying to be set on a copy of a slice from a DataFrame.\n",
      "Try using .loc[row_indexer,col_indexer] = value instead\n",
      "\n",
      "See the caveats in the documentation: https://pandas.pydata.org/pandas-docs/stable/user_guide/indexing.html#returning-a-view-versus-a-copy\n",
      "  df['TIMESTAMP'] = df['TIMESTAMP'].astype(str)\n",
      "C:\\Users\\joearthur\\AppData\\Local\\Temp\\ipykernel_33048\\56103037.py:4: SettingWithCopyWarning: \n",
      "A value is trying to be set on a copy of a slice from a DataFrame.\n",
      "Try using .loc[row_indexer,col_indexer] = value instead\n",
      "\n",
      "See the caveats in the documentation: https://pandas.pydata.org/pandas-docs/stable/user_guide/indexing.html#returning-a-view-versus-a-copy\n",
      "  df['TIMESTAMP'] = df['TIMESTAMP'].astype(str)\n"
     ]
    }
   ],
   "source": [
    "# Loop through each dataset in the dictionary and filter based on the day\n",
    "for key, df in datasets.items():\n",
    "    # Convert the 'TIMESTAMP' column to string (if it's not already)\n",
    "    df['TIMESTAMP'] = df['TIMESTAMP'].astype(str)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "5305b6ed",
   "metadata": {},
   "outputs": [],
   "source": [
    "site_info = {\n",
    "    'AU_GIN': {'Site': 'AU_GIN', 'LandType': 'GRA'},\n",
    "    'GH_ANK': {'Site': 'GH_ANK', 'LandType': 'EBF'},\n",
    "    'DE_RUS': {'Site': 'DE_RUS', 'LandType': 'CRO'},\n",
    "    'GF_GUY': {'Site': 'GF_GUY', 'LandType': 'EBF'},\n",
    "    'US_PFA': {'Site': 'US_PFA', 'LandType': 'MF'},\n",
    "    'US_SRM': {'Site': 'US_SRM', 'LandType': 'WSA'},\n",
    "    'CH_CHA': {'Site': 'CH_CHA', 'LandType': 'GRA'},\n",
    "    'IT_COL': {'Site': 'IT_COL', 'LandType': 'DBF'},\n",
    "    'US_WCR': {'Site': 'US_WCR', 'LandType': 'DBF'},\n",
    "    'AU_CPR': {'Site': 'AU_CPR', 'LandType': 'SAV'},\n",
    "    'US_WKG': {'Site': 'US_WKG', 'LandType': 'GRA'},\n",
    "    'IT_NOE': {'Site': 'IT_NOE', 'LandType': 'CSH'},\n",
    "    'NL_LOO': {'Site': 'NL_LOO', 'LandType': 'ENF'},\n",
    "    'US_NR1': {'Site': 'US_NR1', 'LandType': 'ENF'},\n",
    "    'FR_PUE': {'Site': 'FR_PUE', 'LandType': 'EBF'}\n",
    "}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "113caa6c",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\joearthur\\AppData\\Local\\Temp\\ipykernel_33048\\3613166346.py:3: SettingWithCopyWarning: \n",
      "A value is trying to be set on a copy of a slice from a DataFrame.\n",
      "Try using .loc[row_indexer,col_indexer] = value instead\n",
      "\n",
      "See the caveats in the documentation: https://pandas.pydata.org/pandas-docs/stable/user_guide/indexing.html#returning-a-view-versus-a-copy\n",
      "  df['Site'] = site_info[key]['Site']\n",
      "C:\\Users\\joearthur\\AppData\\Local\\Temp\\ipykernel_33048\\3613166346.py:4: SettingWithCopyWarning: \n",
      "A value is trying to be set on a copy of a slice from a DataFrame.\n",
      "Try using .loc[row_indexer,col_indexer] = value instead\n",
      "\n",
      "See the caveats in the documentation: https://pandas.pydata.org/pandas-docs/stable/user_guide/indexing.html#returning-a-view-versus-a-copy\n",
      "  df['LandType'] = site_info[key]['LandType']\n",
      "C:\\Users\\joearthur\\AppData\\Local\\Temp\\ipykernel_33048\\3613166346.py:3: SettingWithCopyWarning: \n",
      "A value is trying to be set on a copy of a slice from a DataFrame.\n",
      "Try using .loc[row_indexer,col_indexer] = value instead\n",
      "\n",
      "See the caveats in the documentation: https://pandas.pydata.org/pandas-docs/stable/user_guide/indexing.html#returning-a-view-versus-a-copy\n",
      "  df['Site'] = site_info[key]['Site']\n",
      "C:\\Users\\joearthur\\AppData\\Local\\Temp\\ipykernel_33048\\3613166346.py:4: SettingWithCopyWarning: \n",
      "A value is trying to be set on a copy of a slice from a DataFrame.\n",
      "Try using .loc[row_indexer,col_indexer] = value instead\n",
      "\n",
      "See the caveats in the documentation: https://pandas.pydata.org/pandas-docs/stable/user_guide/indexing.html#returning-a-view-versus-a-copy\n",
      "  df['LandType'] = site_info[key]['LandType']\n",
      "C:\\Users\\joearthur\\AppData\\Local\\Temp\\ipykernel_33048\\3613166346.py:3: SettingWithCopyWarning: \n",
      "A value is trying to be set on a copy of a slice from a DataFrame.\n",
      "Try using .loc[row_indexer,col_indexer] = value instead\n",
      "\n",
      "See the caveats in the documentation: https://pandas.pydata.org/pandas-docs/stable/user_guide/indexing.html#returning-a-view-versus-a-copy\n",
      "  df['Site'] = site_info[key]['Site']\n",
      "C:\\Users\\joearthur\\AppData\\Local\\Temp\\ipykernel_33048\\3613166346.py:4: SettingWithCopyWarning: \n",
      "A value is trying to be set on a copy of a slice from a DataFrame.\n",
      "Try using .loc[row_indexer,col_indexer] = value instead\n",
      "\n",
      "See the caveats in the documentation: https://pandas.pydata.org/pandas-docs/stable/user_guide/indexing.html#returning-a-view-versus-a-copy\n",
      "  df['LandType'] = site_info[key]['LandType']\n",
      "C:\\Users\\joearthur\\AppData\\Local\\Temp\\ipykernel_33048\\3613166346.py:3: SettingWithCopyWarning: \n",
      "A value is trying to be set on a copy of a slice from a DataFrame.\n",
      "Try using .loc[row_indexer,col_indexer] = value instead\n",
      "\n",
      "See the caveats in the documentation: https://pandas.pydata.org/pandas-docs/stable/user_guide/indexing.html#returning-a-view-versus-a-copy\n",
      "  df['Site'] = site_info[key]['Site']\n",
      "C:\\Users\\joearthur\\AppData\\Local\\Temp\\ipykernel_33048\\3613166346.py:4: SettingWithCopyWarning: \n",
      "A value is trying to be set on a copy of a slice from a DataFrame.\n",
      "Try using .loc[row_indexer,col_indexer] = value instead\n",
      "\n",
      "See the caveats in the documentation: https://pandas.pydata.org/pandas-docs/stable/user_guide/indexing.html#returning-a-view-versus-a-copy\n",
      "  df['LandType'] = site_info[key]['LandType']\n",
      "C:\\Users\\joearthur\\AppData\\Local\\Temp\\ipykernel_33048\\3613166346.py:3: SettingWithCopyWarning: \n",
      "A value is trying to be set on a copy of a slice from a DataFrame.\n",
      "Try using .loc[row_indexer,col_indexer] = value instead\n",
      "\n",
      "See the caveats in the documentation: https://pandas.pydata.org/pandas-docs/stable/user_guide/indexing.html#returning-a-view-versus-a-copy\n",
      "  df['Site'] = site_info[key]['Site']\n",
      "C:\\Users\\joearthur\\AppData\\Local\\Temp\\ipykernel_33048\\3613166346.py:4: SettingWithCopyWarning: \n",
      "A value is trying to be set on a copy of a slice from a DataFrame.\n",
      "Try using .loc[row_indexer,col_indexer] = value instead\n",
      "\n",
      "See the caveats in the documentation: https://pandas.pydata.org/pandas-docs/stable/user_guide/indexing.html#returning-a-view-versus-a-copy\n",
      "  df['LandType'] = site_info[key]['LandType']\n",
      "C:\\Users\\joearthur\\AppData\\Local\\Temp\\ipykernel_33048\\3613166346.py:3: SettingWithCopyWarning: \n",
      "A value is trying to be set on a copy of a slice from a DataFrame.\n",
      "Try using .loc[row_indexer,col_indexer] = value instead\n",
      "\n",
      "See the caveats in the documentation: https://pandas.pydata.org/pandas-docs/stable/user_guide/indexing.html#returning-a-view-versus-a-copy\n",
      "  df['Site'] = site_info[key]['Site']\n",
      "C:\\Users\\joearthur\\AppData\\Local\\Temp\\ipykernel_33048\\3613166346.py:4: SettingWithCopyWarning: \n",
      "A value is trying to be set on a copy of a slice from a DataFrame.\n",
      "Try using .loc[row_indexer,col_indexer] = value instead\n",
      "\n",
      "See the caveats in the documentation: https://pandas.pydata.org/pandas-docs/stable/user_guide/indexing.html#returning-a-view-versus-a-copy\n",
      "  df['LandType'] = site_info[key]['LandType']\n",
      "C:\\Users\\joearthur\\AppData\\Local\\Temp\\ipykernel_33048\\3613166346.py:3: SettingWithCopyWarning: \n",
      "A value is trying to be set on a copy of a slice from a DataFrame.\n",
      "Try using .loc[row_indexer,col_indexer] = value instead\n",
      "\n",
      "See the caveats in the documentation: https://pandas.pydata.org/pandas-docs/stable/user_guide/indexing.html#returning-a-view-versus-a-copy\n",
      "  df['Site'] = site_info[key]['Site']\n",
      "C:\\Users\\joearthur\\AppData\\Local\\Temp\\ipykernel_33048\\3613166346.py:4: SettingWithCopyWarning: \n",
      "A value is trying to be set on a copy of a slice from a DataFrame.\n",
      "Try using .loc[row_indexer,col_indexer] = value instead\n",
      "\n",
      "See the caveats in the documentation: https://pandas.pydata.org/pandas-docs/stable/user_guide/indexing.html#returning-a-view-versus-a-copy\n",
      "  df['LandType'] = site_info[key]['LandType']\n",
      "C:\\Users\\joearthur\\AppData\\Local\\Temp\\ipykernel_33048\\3613166346.py:3: SettingWithCopyWarning: \n",
      "A value is trying to be set on a copy of a slice from a DataFrame.\n",
      "Try using .loc[row_indexer,col_indexer] = value instead\n",
      "\n",
      "See the caveats in the documentation: https://pandas.pydata.org/pandas-docs/stable/user_guide/indexing.html#returning-a-view-versus-a-copy\n",
      "  df['Site'] = site_info[key]['Site']\n",
      "C:\\Users\\joearthur\\AppData\\Local\\Temp\\ipykernel_33048\\3613166346.py:4: SettingWithCopyWarning: \n",
      "A value is trying to be set on a copy of a slice from a DataFrame.\n",
      "Try using .loc[row_indexer,col_indexer] = value instead\n",
      "\n",
      "See the caveats in the documentation: https://pandas.pydata.org/pandas-docs/stable/user_guide/indexing.html#returning-a-view-versus-a-copy\n",
      "  df['LandType'] = site_info[key]['LandType']\n",
      "C:\\Users\\joearthur\\AppData\\Local\\Temp\\ipykernel_33048\\3613166346.py:3: SettingWithCopyWarning: \n",
      "A value is trying to be set on a copy of a slice from a DataFrame.\n",
      "Try using .loc[row_indexer,col_indexer] = value instead\n",
      "\n",
      "See the caveats in the documentation: https://pandas.pydata.org/pandas-docs/stable/user_guide/indexing.html#returning-a-view-versus-a-copy\n",
      "  df['Site'] = site_info[key]['Site']\n",
      "C:\\Users\\joearthur\\AppData\\Local\\Temp\\ipykernel_33048\\3613166346.py:4: SettingWithCopyWarning: \n",
      "A value is trying to be set on a copy of a slice from a DataFrame.\n",
      "Try using .loc[row_indexer,col_indexer] = value instead\n",
      "\n",
      "See the caveats in the documentation: https://pandas.pydata.org/pandas-docs/stable/user_guide/indexing.html#returning-a-view-versus-a-copy\n",
      "  df['LandType'] = site_info[key]['LandType']\n",
      "C:\\Users\\joearthur\\AppData\\Local\\Temp\\ipykernel_33048\\3613166346.py:3: SettingWithCopyWarning: \n",
      "A value is trying to be set on a copy of a slice from a DataFrame.\n",
      "Try using .loc[row_indexer,col_indexer] = value instead\n",
      "\n",
      "See the caveats in the documentation: https://pandas.pydata.org/pandas-docs/stable/user_guide/indexing.html#returning-a-view-versus-a-copy\n",
      "  df['Site'] = site_info[key]['Site']\n",
      "C:\\Users\\joearthur\\AppData\\Local\\Temp\\ipykernel_33048\\3613166346.py:4: SettingWithCopyWarning: \n",
      "A value is trying to be set on a copy of a slice from a DataFrame.\n",
      "Try using .loc[row_indexer,col_indexer] = value instead\n",
      "\n",
      "See the caveats in the documentation: https://pandas.pydata.org/pandas-docs/stable/user_guide/indexing.html#returning-a-view-versus-a-copy\n",
      "  df['LandType'] = site_info[key]['LandType']\n",
      "C:\\Users\\joearthur\\AppData\\Local\\Temp\\ipykernel_33048\\3613166346.py:3: SettingWithCopyWarning: \n",
      "A value is trying to be set on a copy of a slice from a DataFrame.\n",
      "Try using .loc[row_indexer,col_indexer] = value instead\n",
      "\n",
      "See the caveats in the documentation: https://pandas.pydata.org/pandas-docs/stable/user_guide/indexing.html#returning-a-view-versus-a-copy\n",
      "  df['Site'] = site_info[key]['Site']\n",
      "C:\\Users\\joearthur\\AppData\\Local\\Temp\\ipykernel_33048\\3613166346.py:4: SettingWithCopyWarning: \n",
      "A value is trying to be set on a copy of a slice from a DataFrame.\n",
      "Try using .loc[row_indexer,col_indexer] = value instead\n",
      "\n",
      "See the caveats in the documentation: https://pandas.pydata.org/pandas-docs/stable/user_guide/indexing.html#returning-a-view-versus-a-copy\n",
      "  df['LandType'] = site_info[key]['LandType']\n",
      "C:\\Users\\joearthur\\AppData\\Local\\Temp\\ipykernel_33048\\3613166346.py:3: SettingWithCopyWarning: \n",
      "A value is trying to be set on a copy of a slice from a DataFrame.\n",
      "Try using .loc[row_indexer,col_indexer] = value instead\n",
      "\n",
      "See the caveats in the documentation: https://pandas.pydata.org/pandas-docs/stable/user_guide/indexing.html#returning-a-view-versus-a-copy\n",
      "  df['Site'] = site_info[key]['Site']\n",
      "C:\\Users\\joearthur\\AppData\\Local\\Temp\\ipykernel_33048\\3613166346.py:4: SettingWithCopyWarning: \n",
      "A value is trying to be set on a copy of a slice from a DataFrame.\n",
      "Try using .loc[row_indexer,col_indexer] = value instead\n",
      "\n",
      "See the caveats in the documentation: https://pandas.pydata.org/pandas-docs/stable/user_guide/indexing.html#returning-a-view-versus-a-copy\n",
      "  df['LandType'] = site_info[key]['LandType']\n",
      "C:\\Users\\joearthur\\AppData\\Local\\Temp\\ipykernel_33048\\3613166346.py:3: SettingWithCopyWarning: \n",
      "A value is trying to be set on a copy of a slice from a DataFrame.\n",
      "Try using .loc[row_indexer,col_indexer] = value instead\n",
      "\n",
      "See the caveats in the documentation: https://pandas.pydata.org/pandas-docs/stable/user_guide/indexing.html#returning-a-view-versus-a-copy\n",
      "  df['Site'] = site_info[key]['Site']\n",
      "C:\\Users\\joearthur\\AppData\\Local\\Temp\\ipykernel_33048\\3613166346.py:4: SettingWithCopyWarning: \n",
      "A value is trying to be set on a copy of a slice from a DataFrame.\n",
      "Try using .loc[row_indexer,col_indexer] = value instead\n",
      "\n",
      "See the caveats in the documentation: https://pandas.pydata.org/pandas-docs/stable/user_guide/indexing.html#returning-a-view-versus-a-copy\n",
      "  df['LandType'] = site_info[key]['LandType']\n",
      "C:\\Users\\joearthur\\AppData\\Local\\Temp\\ipykernel_33048\\3613166346.py:3: SettingWithCopyWarning: \n",
      "A value is trying to be set on a copy of a slice from a DataFrame.\n",
      "Try using .loc[row_indexer,col_indexer] = value instead\n",
      "\n",
      "See the caveats in the documentation: https://pandas.pydata.org/pandas-docs/stable/user_guide/indexing.html#returning-a-view-versus-a-copy\n",
      "  df['Site'] = site_info[key]['Site']\n",
      "C:\\Users\\joearthur\\AppData\\Local\\Temp\\ipykernel_33048\\3613166346.py:4: SettingWithCopyWarning: \n",
      "A value is trying to be set on a copy of a slice from a DataFrame.\n",
      "Try using .loc[row_indexer,col_indexer] = value instead\n",
      "\n",
      "See the caveats in the documentation: https://pandas.pydata.org/pandas-docs/stable/user_guide/indexing.html#returning-a-view-versus-a-copy\n",
      "  df['LandType'] = site_info[key]['LandType']\n",
      "C:\\Users\\joearthur\\AppData\\Local\\Temp\\ipykernel_33048\\3613166346.py:3: SettingWithCopyWarning: \n",
      "A value is trying to be set on a copy of a slice from a DataFrame.\n",
      "Try using .loc[row_indexer,col_indexer] = value instead\n",
      "\n",
      "See the caveats in the documentation: https://pandas.pydata.org/pandas-docs/stable/user_guide/indexing.html#returning-a-view-versus-a-copy\n",
      "  df['Site'] = site_info[key]['Site']\n",
      "C:\\Users\\joearthur\\AppData\\Local\\Temp\\ipykernel_33048\\3613166346.py:4: SettingWithCopyWarning: \n",
      "A value is trying to be set on a copy of a slice from a DataFrame.\n",
      "Try using .loc[row_indexer,col_indexer] = value instead\n",
      "\n",
      "See the caveats in the documentation: https://pandas.pydata.org/pandas-docs/stable/user_guide/indexing.html#returning-a-view-versus-a-copy\n",
      "  df['LandType'] = site_info[key]['LandType']\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>TIMESTAMP</th>\n",
       "      <th>Site</th>\n",
       "      <th>LandType</th>\n",
       "      <th>GPP_DT_VUT_REF</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>20120101</td>\n",
       "      <td>AU_CPR</td>\n",
       "      <td>SAV</td>\n",
       "      <td>2.03879</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>20120102</td>\n",
       "      <td>AU_CPR</td>\n",
       "      <td>SAV</td>\n",
       "      <td>1.87470</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>20120103</td>\n",
       "      <td>AU_CPR</td>\n",
       "      <td>SAV</td>\n",
       "      <td>1.78140</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>20120104</td>\n",
       "      <td>AU_CPR</td>\n",
       "      <td>SAV</td>\n",
       "      <td>3.02629</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>20120105</td>\n",
       "      <td>AU_CPR</td>\n",
       "      <td>SAV</td>\n",
       "      <td>3.02008</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>14866</th>\n",
       "      <td>20141227</td>\n",
       "      <td>AU_GIN</td>\n",
       "      <td>GRA</td>\n",
       "      <td>3.73948</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>14867</th>\n",
       "      <td>20141228</td>\n",
       "      <td>AU_GIN</td>\n",
       "      <td>GRA</td>\n",
       "      <td>4.45458</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>14868</th>\n",
       "      <td>20141229</td>\n",
       "      <td>AU_GIN</td>\n",
       "      <td>GRA</td>\n",
       "      <td>3.83001</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>14869</th>\n",
       "      <td>20141230</td>\n",
       "      <td>AU_GIN</td>\n",
       "      <td>GRA</td>\n",
       "      <td>3.36805</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>14870</th>\n",
       "      <td>20141231</td>\n",
       "      <td>AU_GIN</td>\n",
       "      <td>GRA</td>\n",
       "      <td>4.63954</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>14871 rows × 4 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "      TIMESTAMP    Site LandType  GPP_DT_VUT_REF\n",
       "0      20120101  AU_CPR      SAV         2.03879\n",
       "1      20120102  AU_CPR      SAV         1.87470\n",
       "2      20120103  AU_CPR      SAV         1.78140\n",
       "3      20120104  AU_CPR      SAV         3.02629\n",
       "4      20120105  AU_CPR      SAV         3.02008\n",
       "...         ...     ...      ...             ...\n",
       "14866  20141227  AU_GIN      GRA         3.73948\n",
       "14867  20141228  AU_GIN      GRA         4.45458\n",
       "14868  20141229  AU_GIN      GRA         3.83001\n",
       "14869  20141230  AU_GIN      GRA         3.36805\n",
       "14870  20141231  AU_GIN      GRA         4.63954\n",
       "\n",
       "[14871 rows x 4 columns]"
      ]
     },
     "execution_count": 8,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Loop through each dataset, add 'Site' and 'LandType' columns\n",
    "for key, df in datasets.items():\n",
    "    df['Site'] = site_info[key]['Site']\n",
    "    df['LandType'] = site_info[key]['LandType']\n",
    "\n",
    "# Concatenate all datasets into a single DataFrame\n",
    "final_df = pd.concat(datasets.values(), ignore_index=True)\n",
    "final_df = final_df[['TIMESTAMP','Site','LandType','GPP_DT_VUT_REF']]\n",
    "# Display the concatenated DataFrame\n",
    "final_df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "2d4d9a36",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "Site\n",
       "FR_PUE    1096\n",
       "GF_GUY    1096\n",
       "IT_NOE    1096\n",
       "AU_GIN    1096\n",
       "NL_LOO    1095\n",
       "CH_CHA    1094\n",
       "US_SRM    1068\n",
       "DE_RUS    1054\n",
       "US_WKG    1020\n",
       "AU_CPR     972\n",
       "IT_COL     966\n",
       "US_NR1     913\n",
       "US_PFA     874\n",
       "GH_ANK     731\n",
       "US_WCR     700\n",
       "Name: count, dtype: int64"
      ]
     },
     "execution_count": 9,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "final_df['Site'].value_counts()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "623a2cfd",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Date</th>\n",
       "      <th>Site</th>\n",
       "      <th>LandType</th>\n",
       "      <th>GPP_DT_VUT_REF</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>2012-01-01</td>\n",
       "      <td>AU_CPR</td>\n",
       "      <td>SAV</td>\n",
       "      <td>2.03879</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>2012-01-02</td>\n",
       "      <td>AU_CPR</td>\n",
       "      <td>SAV</td>\n",
       "      <td>1.87470</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>2012-01-03</td>\n",
       "      <td>AU_CPR</td>\n",
       "      <td>SAV</td>\n",
       "      <td>1.78140</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>2012-01-04</td>\n",
       "      <td>AU_CPR</td>\n",
       "      <td>SAV</td>\n",
       "      <td>3.02629</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>2012-01-05</td>\n",
       "      <td>AU_CPR</td>\n",
       "      <td>SAV</td>\n",
       "      <td>3.02008</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>14866</th>\n",
       "      <td>2014-12-27</td>\n",
       "      <td>AU_GIN</td>\n",
       "      <td>GRA</td>\n",
       "      <td>3.73948</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>14867</th>\n",
       "      <td>2014-12-28</td>\n",
       "      <td>AU_GIN</td>\n",
       "      <td>GRA</td>\n",
       "      <td>4.45458</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>14868</th>\n",
       "      <td>2014-12-29</td>\n",
       "      <td>AU_GIN</td>\n",
       "      <td>GRA</td>\n",
       "      <td>3.83001</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>14869</th>\n",
       "      <td>2014-12-30</td>\n",
       "      <td>AU_GIN</td>\n",
       "      <td>GRA</td>\n",
       "      <td>3.36805</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>14870</th>\n",
       "      <td>2014-12-31</td>\n",
       "      <td>AU_GIN</td>\n",
       "      <td>GRA</td>\n",
       "      <td>4.63954</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>14871 rows × 4 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "             Date    Site LandType  GPP_DT_VUT_REF\n",
       "0      2012-01-01  AU_CPR      SAV         2.03879\n",
       "1      2012-01-02  AU_CPR      SAV         1.87470\n",
       "2      2012-01-03  AU_CPR      SAV         1.78140\n",
       "3      2012-01-04  AU_CPR      SAV         3.02629\n",
       "4      2012-01-05  AU_CPR      SAV         3.02008\n",
       "...           ...     ...      ...             ...\n",
       "14866  2014-12-27  AU_GIN      GRA         3.73948\n",
       "14867  2014-12-28  AU_GIN      GRA         4.45458\n",
       "14868  2014-12-29  AU_GIN      GRA         3.83001\n",
       "14869  2014-12-30  AU_GIN      GRA         3.36805\n",
       "14870  2014-12-31  AU_GIN      GRA         4.63954\n",
       "\n",
       "[14871 rows x 4 columns]"
      ]
     },
     "execution_count": 10,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "final_df['TIMESTAMP'] = pd.to_datetime(final_df['TIMESTAMP'], format='%Y%m%d')\n",
    "final_df['TIMESTAMP'] = final_df['TIMESTAMP'].dt.strftime('%Y-%m-%d')\n",
    "final_df.rename(columns={'TIMESTAMP': 'Date'}, inplace=True)\n",
    "final_df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "4cc98bd1",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Date</th>\n",
       "      <th>Site</th>\n",
       "      <th>LandType</th>\n",
       "      <th>GPP_DT_VUT_REF</th>\n",
       "      <th>Day</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>2012-01-01</td>\n",
       "      <td>AU_CPR</td>\n",
       "      <td>SAV</td>\n",
       "      <td>2.03879</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>2012-01-02</td>\n",
       "      <td>AU_CPR</td>\n",
       "      <td>SAV</td>\n",
       "      <td>1.87470</td>\n",
       "      <td>2</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>2012-01-03</td>\n",
       "      <td>AU_CPR</td>\n",
       "      <td>SAV</td>\n",
       "      <td>1.78140</td>\n",
       "      <td>3</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>2012-01-04</td>\n",
       "      <td>AU_CPR</td>\n",
       "      <td>SAV</td>\n",
       "      <td>3.02629</td>\n",
       "      <td>4</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>2012-01-05</td>\n",
       "      <td>AU_CPR</td>\n",
       "      <td>SAV</td>\n",
       "      <td>3.02008</td>\n",
       "      <td>5</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>14866</th>\n",
       "      <td>2014-12-27</td>\n",
       "      <td>AU_GIN</td>\n",
       "      <td>GRA</td>\n",
       "      <td>3.73948</td>\n",
       "      <td>27</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>14867</th>\n",
       "      <td>2014-12-28</td>\n",
       "      <td>AU_GIN</td>\n",
       "      <td>GRA</td>\n",
       "      <td>4.45458</td>\n",
       "      <td>28</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>14868</th>\n",
       "      <td>2014-12-29</td>\n",
       "      <td>AU_GIN</td>\n",
       "      <td>GRA</td>\n",
       "      <td>3.83001</td>\n",
       "      <td>29</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>14869</th>\n",
       "      <td>2014-12-30</td>\n",
       "      <td>AU_GIN</td>\n",
       "      <td>GRA</td>\n",
       "      <td>3.36805</td>\n",
       "      <td>30</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>14870</th>\n",
       "      <td>2014-12-31</td>\n",
       "      <td>AU_GIN</td>\n",
       "      <td>GRA</td>\n",
       "      <td>4.63954</td>\n",
       "      <td>31</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>14871 rows × 5 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "            Date    Site LandType  GPP_DT_VUT_REF  Day\n",
       "0     2012-01-01  AU_CPR      SAV         2.03879    1\n",
       "1     2012-01-02  AU_CPR      SAV         1.87470    2\n",
       "2     2012-01-03  AU_CPR      SAV         1.78140    3\n",
       "3     2012-01-04  AU_CPR      SAV         3.02629    4\n",
       "4     2012-01-05  AU_CPR      SAV         3.02008    5\n",
       "...          ...     ...      ...             ...  ...\n",
       "14866 2014-12-27  AU_GIN      GRA         3.73948   27\n",
       "14867 2014-12-28  AU_GIN      GRA         4.45458   28\n",
       "14868 2014-12-29  AU_GIN      GRA         3.83001   29\n",
       "14869 2014-12-30  AU_GIN      GRA         3.36805   30\n",
       "14870 2014-12-31  AU_GIN      GRA         4.63954   31\n",
       "\n",
       "[14871 rows x 5 columns]"
      ]
     },
     "execution_count": 11,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "final_df['Date'] = pd.to_datetime(final_df['Date'])\n",
    "final_df['Day'] = final_df['Date'].dt.day\n",
    "final_df"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "6d62ebd6",
   "metadata": {},
   "source": [
    "Filtering dataset based on most available dates as to reduce dataset size for efficiency reasons"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "5dd3e116",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "Day\n",
       "14    496\n",
       "12    496\n",
       "13    495\n",
       "11    493\n",
       "15    492\n",
       "28    491\n",
       "18    489\n",
       "17    489\n",
       "16    489\n",
       "26    488\n",
       "25    488\n",
       "7     488\n",
       "27    488\n",
       "24    488\n",
       "23    488\n",
       "4     488\n",
       "19    487\n",
       "21    487\n",
       "10    487\n",
       "2     487\n",
       "8     487\n",
       "9     486\n",
       "22    486\n",
       "6     486\n",
       "20    485\n",
       "3     485\n",
       "1     484\n",
       "5     484\n",
       "29    467\n",
       "30    449\n",
       "31    278\n",
       "Name: count, dtype: int64"
      ]
     },
     "execution_count": 12,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "final_df['Day'].value_counts()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "6d02010b",
   "metadata": {},
   "source": [
    "Top 10 Days = 11,12,13,14,15,16,18,21,26,28"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "dad3d9d5",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Date</th>\n",
       "      <th>Site</th>\n",
       "      <th>LandType</th>\n",
       "      <th>GPP_DT_VUT_REF</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>10</th>\n",
       "      <td>2012-01-11</td>\n",
       "      <td>AU_CPR</td>\n",
       "      <td>SAV</td>\n",
       "      <td>3.14294</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>11</th>\n",
       "      <td>2012-01-12</td>\n",
       "      <td>AU_CPR</td>\n",
       "      <td>SAV</td>\n",
       "      <td>3.33879</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>12</th>\n",
       "      <td>2012-01-13</td>\n",
       "      <td>AU_CPR</td>\n",
       "      <td>SAV</td>\n",
       "      <td>2.84944</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>13</th>\n",
       "      <td>2012-01-14</td>\n",
       "      <td>AU_CPR</td>\n",
       "      <td>SAV</td>\n",
       "      <td>3.06008</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>14</th>\n",
       "      <td>2012-01-15</td>\n",
       "      <td>AU_CPR</td>\n",
       "      <td>SAV</td>\n",
       "      <td>2.77582</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>14855</th>\n",
       "      <td>2014-12-16</td>\n",
       "      <td>AU_GIN</td>\n",
       "      <td>GRA</td>\n",
       "      <td>5.86594</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>14857</th>\n",
       "      <td>2014-12-18</td>\n",
       "      <td>AU_GIN</td>\n",
       "      <td>GRA</td>\n",
       "      <td>5.00909</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>14860</th>\n",
       "      <td>2014-12-21</td>\n",
       "      <td>AU_GIN</td>\n",
       "      <td>GRA</td>\n",
       "      <td>5.99877</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>14865</th>\n",
       "      <td>2014-12-26</td>\n",
       "      <td>AU_GIN</td>\n",
       "      <td>GRA</td>\n",
       "      <td>4.55825</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>14867</th>\n",
       "      <td>2014-12-28</td>\n",
       "      <td>AU_GIN</td>\n",
       "      <td>GRA</td>\n",
       "      <td>4.45458</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>4916 rows × 4 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "            Date    Site LandType  GPP_DT_VUT_REF\n",
       "10    2012-01-11  AU_CPR      SAV         3.14294\n",
       "11    2012-01-12  AU_CPR      SAV         3.33879\n",
       "12    2012-01-13  AU_CPR      SAV         2.84944\n",
       "13    2012-01-14  AU_CPR      SAV         3.06008\n",
       "14    2012-01-15  AU_CPR      SAV         2.77582\n",
       "...          ...     ...      ...             ...\n",
       "14855 2014-12-16  AU_GIN      GRA         5.86594\n",
       "14857 2014-12-18  AU_GIN      GRA         5.00909\n",
       "14860 2014-12-21  AU_GIN      GRA         5.99877\n",
       "14865 2014-12-26  AU_GIN      GRA         4.55825\n",
       "14867 2014-12-28  AU_GIN      GRA         4.45458\n",
       "\n",
       "[4916 rows x 4 columns]"
      ]
     },
     "execution_count": 13,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "days = [11,12,13,14,15,16,18,21,26,28]\n",
    "\n",
    "final = final_df[final_df['Day'].isin(days)]\n",
    "del final['Day']\n",
    "final"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "id": "bcd4db42",
   "metadata": {},
   "outputs": [],
   "source": [
    "final.to_excel('Final_Flux_Data.xlsx')"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
